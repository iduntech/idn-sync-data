{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import mne\n",
    "import glob\n",
    "import os\n",
    "from pyedflib import highlevel\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.freq_calculator import do_bandpass, prepare_fft\n",
    "import copy\n",
    "import pyxdf\n",
    "\n",
    "\n",
    "from utils.lag_calculator import (\n",
    "    epoch_data,\n",
    "    remove_outliers,\n",
    "    replace_outliers,\n",
    "    calculate_epochs_lag,\n",
    "    prepare_comparison_data,\n",
    "    prepare_idun_data,\n",
    "    adjust_data_by_mean_lag,\n",
    "    sync_start_and_equalize_data_length,\n",
    "    clean_data_from_spikes,\n",
    "    convert_data_to_array,\n",
    "    get_device_configuration,\n",
    "    cut_throughout_data_dual,\n",
    "    interpolate_signal,\n",
    "    smooth,\n",
    "    manual_sync\n",
    ")\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyedflib\n",
    "comparison_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mne\n",
    "mne_comparison_raw_data[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = \"Fullscalp\"\n",
    "# subject = \"SB\"\n",
    "folder = \"/Users/eliasmeier/Documents/IDUN/Data/Eurostars_Cerebra/ORP_inear_adaptation/01_Pre_study\"\n",
    "subject = \"S001\"\n",
    "night = \"night1\"\n",
    "idun_file_ending = \"eeg\"\n",
    "\n",
    "\n",
    "if len(glob.glob(os.path.join(folder, subject, night, \"*scoring.edf\"))) != 0:\n",
    "    edf_file_path = glob.glob(os.path.join(folder, subject, night, \"*scoring.edf\"))[0]\n",
    "    print(edf_file_path)\n",
    "    mne_comparison_raw_data = mne.io.read_raw_edf(edf_file_path, preload=True)\n",
    "    comparison_raw_data = highlevel.read_edf(edf_file_path)\n",
    "    \n",
    "    # iterate to initial file to match format of mne edf reader\n",
    "    # TODO: Does this work? Arrays are of different length\n",
    "    #comparison_raw_data = []\n",
    "    #for row in edf_data:\n",
    "    #    comparison_raw_data.append(np.array(row))\n",
    "\n",
    "    #create timestamp array \n",
    "    samp_rate = comparison_raw_data[1][1]['sample_rate']\n",
    "    sample_count = len(comparison_raw_data[0][1]) # select channel that has 120Hz sampling freq\n",
    "    increment = 1/samp_rate # increase in these increments based on prodigy EEG channel sampling rate\n",
    "    comparison_time_stamps = np.arange(0, sample_count*increment, increment)\n",
    "    \n",
    "    file_extention = \"edf\"\n",
    "else:\n",
    "    print(\"No edf file present in the folder\")\n",
    "if len(glob.glob(os.path.join(folder, subject, night, \"*.xdf\"))) != 0:\n",
    "    xdf_file_path = glob.glob(os.path.join(folder, subject, night, \"*.xdf\"))[0]\n",
    "    print(xdf_file_path)\n",
    "    comparison_raw_data, comparison_raw_header = pyxdf.load_xdf(xdf_file_path)\n",
    "    comparison_time_stamps = comparison_raw_data[0][\"time_stamps\"]\n",
    "    file_extention = \"xdf\"\n",
    "else:\n",
    "    print(\"No xdf file present in the folder\")\n",
    "\n",
    "# csv_file_path = glob.glob(os.path.join(folder, subject, night, \"*eeg.csv\"))[0]\n",
    "csv_file_path = glob.glob(\n",
    "    os.path.join(folder, subject, night, f\"*{idun_file_ending}.csv\")\n",
    ")[0]\n",
    "\n",
    "# upload csv file using numpy\n",
    "idun_raw_data = np.genfromtxt(csv_file_path, delimiter=\",\", skip_header=1)\n",
    "# print the paths\n",
    "\n",
    "print(csv_file_path)\n",
    "channel_1_key, channel_2_key, scale_factor, sample_rate = get_device_configuration(\n",
    "    config\n",
    ")\n",
    "# print channel keys\n",
    "print(channel_1_key, channel_2_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpack scalp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_data, comparison_channel_names = convert_data_to_array(\n",
    "    comparison_raw_data, file_extention\n",
    "\n",
    ")\n",
    "\n",
    "(\n",
    "    comparison_base_data_df,\n",
    "    comparison_filtered_data_rs,\n",
    "    resampled_times,\n",
    ") = prepare_comparison_data(comparison_data, config)\n",
    "pr_freqs_rs, pr_fft_rs = prepare_fft(\n",
    "    comparison_filtered_data_rs,\n",
    "    config.FILTER_RANGE[0] - 5,\n",
    "    config.FILTER_RANGE[1] + 5,\n",
    "    config.BASE_SAMPLE_RATE,\n",
    ")\n",
    "# print columns of the dataframe\n",
    "print(comparison_base_data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 2))\n",
    "plt.plot(resampled_times, comparison_filtered_data_rs)\n",
    "plt.title(\"Channel 1 - Channel 2  Filtered data\")\n",
    "plt.ylim(-200, 200)\n",
    "# Plot the fft of the data\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.plot(\n",
    "    resampled_times,\n",
    "    (comparison_base_data_df[channel_1_key] - comparison_base_data_df[channel_2_key])\n",
    "    * scale_factor,\n",
    ")\n",
    "plt.title(\"Channel 1 - Channel 2 unfiltered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpack IDUN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idun_base_data, idun_filtered_data, idun_time_stamps = prepare_idun_data(\n",
    "    idun_raw_data, config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 2))\n",
    "plt.plot(idun_time_stamps, idun_filtered_data)\n",
    "plt.ylim(-200, 200)\n",
    "plt.title(\"IDUN EMG filtered data\")\n",
    "\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.plot(idun_time_stamps, idun_base_data)\n",
    "plt.ylim(-200, 200)\n",
    "plt.title(\"IDUN Highpassed data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axis\n",
    "plt.figure(figsize=(15, 2))  # Adjust the figsize as needed\n",
    "ax = plt.gca()\n",
    "plt.plot(\n",
    "    resampled_times,\n",
    "    comparison_filtered_data_rs,\n",
    "    label=\"Channel 1 - Channel 2 Filtered Data\",\n",
    ")\n",
    "plt.plot(idun_time_stamps, idun_filtered_data, label=\"IDUN EMG Filtered Data\")\n",
    "plt.ylim(-200, 200)\n",
    "plt.legend()\n",
    "plt.title(\"Superimposed Filtered Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data same length and do auto shifting based on time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use the function\n",
    "(\n",
    "    comparison_clipped_data,\n",
    "    idun_clipped_data,\n",
    "    idun_base_clipped_data,\n",
    "    comparison_base_clipped_df,\n",
    "    same_times,\n",
    ") = sync_start_and_equalize_data_length(\n",
    "    comparison_filtered_data_rs,\n",
    "    idun_filtered_data,\n",
    "    idun_base_data,\n",
    "    comparison_base_data_df,\n",
    "    comparison_time_stamps,\n",
    "    idun_time_stamps,\n",
    "    config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do extra shift if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_clipped_data_manual, idun_clipped_data_manual, idun_base_clipped_data_manual, comparison_base_clipped_df_manual, same_times = manual_sync(comparison_clipped_data, idun_clipped_data, idun_base_clipped_data, comparison_base_clipped_df, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_start = 0\n",
    "range_viz = 25000\n",
    "# create indeces from second limits\n",
    "x_start_index = int(x_start * config.BASE_SAMPLE_RATE)\n",
    "range_viz_index = int(range_viz * config.BASE_SAMPLE_RATE)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.plot(\n",
    "    same_times[x_start_index : x_start_index + range_viz_index],\n",
    "    idun_clipped_data_manual[x_start_index : x_start_index + range_viz_index],\n",
    "    label=\"idun\",\n",
    ")\n",
    "plt.plot(\n",
    "    same_times[x_start_index : x_start_index + range_viz_index],\n",
    "    0.5 * comparison_clipped_data_manual[x_start_index : x_start_index + range_viz_index],\n",
    "    label=config.DEVICE,\n",
    ")\n",
    "plt.legend(\"lower right\")\n",
    "plt.ylim(-100, 100)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate lag first iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only the first 1000 seconds\n",
    "comparison_clipped_temp_data = copy.deepcopy(comparison_clipped_data_manual)\n",
    "idun_clipped_temp_data = copy.deepcopy(idun_clipped_data_manual)\n",
    "\n",
    "search_size = config.FIRST_LAG_EPOCH_SIZE\n",
    "\n",
    "comparison_epochs = epoch_data(comparison_clipped_temp_data, search_size)\n",
    "idun_epochs = epoch_data(idun_clipped_temp_data, search_size)\n",
    "# extract only the f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_arr, max_corr_arr, lag_arr = calculate_epochs_lag(\n",
    "    comparison_epochs, idun_epochs\n",
    ")\n",
    "lag_arr_copy = lag_arr[1:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 2))\n",
    "# create a time array based on config.FIRST_LAG_EPOCH_SIZE and length of lag_arr_copy\n",
    "plot_time_arr = np.linspace(\n",
    "    0, len(lag_arr_copy) * config.FIRST_LAG_EPOCH_SIZE, len(lag_arr_copy)\n",
    ")\n",
    "# convert  to seconds\n",
    "plot_time_arr = plot_time_arr / config.BASE_SAMPLE_RATE\n",
    "plt.title(\"Lag over time\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Lag (s)\")\n",
    "plt.plot(plot_time_arr, np.array(lag_arr_copy) / config.BASE_SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut based on first analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_arr = np.array(lag_arr)\n",
    "lag_initial = lag_arr[:20]\n",
    "lag_initial = remove_outliers(lag_initial)\n",
    "lag_mean = lag_initial[0]\n",
    "\n",
    "# cut the lag_mean data from the start of idun_clipped_data if it is positive or from the start of  if negative\n",
    "if lag_mean < 0:\n",
    "    idun_cut_data = idun_clipped_data_manual[-lag_mean:]\n",
    "    idun_base_cut_data = idun_base_clipped_data_manual[-lag_mean:]\n",
    "    comparison_cut_data = comparison_clipped_data_manual[:-(-lag_mean)]\n",
    "    comparison_base_cut_df = comparison_base_clipped_df_manual[:-(-lag_mean)].reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "else:\n",
    "    idun_cut_data = idun_clipped_data_manual[:-(lag_mean)]\n",
    "    idun_base_cut_data = idun_base_clipped_data_manual[:-(lag_mean)]\n",
    "    comparison_cut_data = comparison_clipped_data_manual[lag_mean:]\n",
    "    comparison_base_cut_df = comparison_base_clipped_df_manual[lag_mean:].reset_index(\n",
    "        drop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.plot(lag_initial / config.BASE_SAMPLE_RATE, label=\"idun\")\n",
    "print(\"lag_mean: \", lag_mean / config.BASE_SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "plt.figure(figsize=(15, 2))\n",
    "time_seconds = np.arange(len(idun_cut_data)) / config.BASE_SAMPLE_RATE\n",
    "plt.plot(\n",
    "    time_seconds[x_start_index : x_start_index + range_viz_index],\n",
    "    idun_cut_data[x_start_index : x_start_index + range_viz_index],\n",
    "    label=\"idun\",\n",
    ")\n",
    "plt.plot(\n",
    "    time_seconds[x_start_index : x_start_index + range_viz_index],\n",
    "    0.5 * comparison_cut_data[x_start_index : x_start_index + range_viz_index],\n",
    "    label=config.DEVICE,\n",
    ")\n",
    "plt.legend(\"lower right\")\n",
    "plt.ylim(-100, 100)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a more fine grained sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutted_comparisoneeg_epochs = epoch_data(\n",
    "    comparison_cut_data, config.SECOND_LAG_EPOCH_SIZE\n",
    ")\n",
    "cutted_idun_epochs = epoch_data(idun_cut_data, config.SECOND_LAG_EPOCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_correlation_arr, fine_max_corr_arr, fine_lag_arr = calculate_epochs_lag(\n",
    "    cutted_comparisoneeg_epochs, cutted_idun_epochs\n",
    ")\n",
    "fine_lag_arr[0] = fine_lag_arr[1]  # the very first lag estimation is not accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_lag_arr_copy = fine_lag_arr.copy()\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.plot(np.array(fine_lag_arr_copy) / 250)\n",
    "plt.title(\"Lag\")\n",
    "plt.xlabel(f\"Epochs of {config.SECOND_LAG_EPOCH_SIZE} samples\")\n",
    "plt.ylabel(\"Lag (s)\")\n",
    "plt.ylim(-15, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do some cleaning on lag estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCONTINUITY_THRESHOLD = config.DISCONTINUITY_THRESHOLD\n",
    "# save as txt file the correlation strictness\n",
    "np.savetxt(\n",
    "    os.path.join(folder, subject, night, \"discontinuity_threshold.txt\"),\n",
    "    [DISCONTINUITY_THRESHOLD],\n",
    "    delimiter=\",\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_fine_lag_arr = clean_data_from_spikes(\n",
    "    fine_lag_arr_copy, DISCONTINUITY_THRESHOLD\n",
    ")\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.plot(cleaned_fine_lag_arr / config.BASE_SAMPLE_RATE)\n",
    "plt.title(\"Lag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make signal whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate the signal\n",
    "interpolated_cleaned_fine_lag_arr = interpolate_signal(cleaned_fine_lag_arr)\n",
    "smoothed_lag_arr = smooth(interpolated_cleaned_fine_lag_arr, window_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the regression curve\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.plot(\n",
    "    cleaned_fine_lag_arr / config.BASE_SAMPLE_RATE,\n",
    "    label=\"Actual Lag estimation\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "plt.plot(\n",
    "    smoothed_lag_arr / config.BASE_SAMPLE_RATE,\n",
    "    \"r-\",\n",
    "    label=\"Final lag estimation\",\n",
    "    linewidth=1,\n",
    ")\n",
    "plt.title(\"Estimation of lag between two devices\")\n",
    "plt.xlabel(\"Time in seconds\")\n",
    "plt.ylabel(\"Lag in seconds\")\n",
    "plt.legend()\n",
    "plt.savefig(\n",
    "    os.path.join(folder, subject, night, \"lag_estimation.png\"),\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create linear knots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis_simulated = np.linspace(\n",
    "    0, len(smoothed_lag_arr) - 1, len(smoothed_lag_arr)\n",
    ")  # This will be 0 to 718\n",
    "\n",
    "x_knots = np.linspace(0, len(smoothed_lag_arr) - 1, config.TOTAL_LINEAR_SEGMENTS + 1)\n",
    "y_knots = smoothed_lag_arr[\n",
    "    (x_knots).astype(int)\n",
    "]  # Directly get the y-values from y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.plot(x_axis_simulated, smoothed_lag_arr, label=\"Original Curve\")\n",
    "plt.plot(\n",
    "    x_knots,\n",
    "    y_knots,\n",
    "    label=f\"{config.TOTAL_LINEAR_SEGMENTS} Linear Segments\",\n",
    "    linestyle=\"--\",\n",
    "    marker=\"o\",\n",
    "    linewidth=1,\n",
    "    markersize=1,\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Linear lines to estimate the difference in sampling rates and apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_size = config.SECOND_LAG_EPOCH_SIZE\n",
    "adjustment_epoch_size = int(len(comparison_cut_data) / config.TOTAL_LINEAR_SEGMENTS)\n",
    "lag_positions = np.arange(0, len(comparison_cut_data), adjustment_epoch_size)\n",
    "cumulative_lags = y_knots.astype(int)\n",
    "lag_sizes = np.diff(cumulative_lags)\n",
    "# make sure lag_sizes and lag_positions have the same length by cutting end of shorter one\n",
    "if len(lag_sizes) > len(lag_positions):\n",
    "    lag_sizes = lag_sizes[: len(lag_positions)]\n",
    "elif len(lag_sizes) < len(lag_positions):\n",
    "    lag_positions = lag_positions[: len(lag_sizes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 2))\n",
    "plt.plot(lag_sizes)\n",
    "plt.title(\"Number of samples to be removed at each lag\")\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.ylim(-10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut the data throughout and at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    idun_data_pruned,\n",
    "    idun_base_pruned,\n",
    "    comparison_data_pruned,\n",
    "    comparison_base_pruned_df,\n",
    ") = cut_throughout_data_dual(\n",
    "    idun_cut_data,\n",
    "    idun_base_cut_data,\n",
    "    comparison_cut_data,\n",
    "    comparison_base_cut_df,\n",
    "    lag_positions,\n",
    "    lag_sizes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_comparison_epochs = epoch_data(\n",
    "    comparison_data_pruned, config.SECOND_LAG_EPOCH_SIZE\n",
    ")\n",
    "final_idun_epochs = epoch_data(idun_data_pruned, config.SECOND_LAG_EPOCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_correlation_arr, final_max_corr_arr, final_lag_arr = calculate_epochs_lag(\n",
    "    final_comparison_epochs, final_idun_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lag_arr_copy = final_lag_arr.copy()\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.plot(np.array(final_lag_arr) / config.BASE_SAMPLE_RATE)\n",
    "plt.title(\"Lag\")\n",
    "plt.ylim(-0.3, 0.3)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_final_lag_arr = replace_outliers(final_lag_arr_copy)\n",
    "# rfind where the values are nan\n",
    "nan_idx = np.argwhere(np.isnan(cleaned_final_lag_arr))\n",
    "# remove the nan values\n",
    "mean_final_lag = np.mean(np.delete(cleaned_final_lag_arr, nan_idx, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 2))\n",
    "plt.plot(np.array(cleaned_final_lag_arr) / config.BASE_SAMPLE_RATE)\n",
    "# plot the mean_final_lag as a horizontal line\n",
    "plt.axhline(y=mean_final_lag / config.BASE_SAMPLE_RATE, color=\"r\", linestyle=\"--\")\n",
    "plt.title(\"Lag\")\n",
    "plt.ylim(-1, 1)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove this final shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    shifted_final_comparisoneeg_arr,\n",
    "    shifted_final_comparisoneeg_base_df,\n",
    "    shifted_final_idun_arr,\n",
    "    shifted_final_idun_base_arr,\n",
    ") = adjust_data_by_mean_lag(\n",
    "    mean_final_lag,\n",
    "    comparison_data_pruned,\n",
    "    comparison_base_pruned_df,\n",
    "    idun_data_pruned,\n",
    "    idun_base_pruned,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_final_comparisoneeg_epochs = epoch_data(\n",
    "    shifted_final_comparisoneeg_arr, config.SECOND_LAG_EPOCH_SIZE\n",
    ")\n",
    "shifted_final_idun_epochs = epoch_data(\n",
    "    shifted_final_idun_arr, config.SECOND_LAG_EPOCH_SIZE\n",
    ")\n",
    "(\n",
    "    shifted_final_correlation_arr,\n",
    "    shifted_final_max_corr_arr,\n",
    "    shifted_final_lag_arr,\n",
    ") = calculate_epochs_lag(shifted_final_comparisoneeg_epochs, shifted_final_idun_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 2))\n",
    "# create time array kby muliplying the length of the array by the epoch size\n",
    "time_seconds = (\n",
    "    np.arange(len(shifted_final_lag_arr))\n",
    "    * config.SECOND_LAG_EPOCH_SIZE\n",
    "    / config.BASE_SAMPLE_RATE\n",
    ")\n",
    "plt.plot(time_seconds, np.array(shifted_final_lag_arr) / config.BASE_SAMPLE_RATE)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.title(\"Lag\")\n",
    "plt.xlabel(\"Time in seconds\")\n",
    "plt.ylabel(\"Lag in seconds\")\n",
    "plt.ylim(-0.05, 0.05)\n",
    "plt.grid()\n",
    "# save image of lag\n",
    "plt.savefig(os.path.join(folder, subject, night, f\"{subject}_{night}_lag.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot final filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 2))\n",
    "# create a seconds axis\n",
    "time_seconds = np.arange(len(shifted_final_idun_arr)) / config.BASE_SAMPLE_RATE\n",
    "plt.plot(shifted_final_idun_arr, label=\"idun\")\n",
    "plt.plot(0.5 * shifted_final_comparisoneeg_arr, label=config.DEVICE)\n",
    "plt.legend()\n",
    "plt.ylim(-100, 100)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final validation, plot final raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shifted_final_comparisoneeg_base_df.shape)\n",
    "print(shifted_final_idun_base_arr.shape)\n",
    "\n",
    "comparisoneeg_channel_1_data = np.array(\n",
    "    shifted_final_comparisoneeg_base_df[channel_1_key]\n",
    ")\n",
    "comparisoneeg_channel_2_data = np.array(\n",
    "    shifted_final_comparisoneeg_base_df[channel_2_key]\n",
    ")\n",
    "# minus right eye from left eye\n",
    "comparisoneeg_channel_1_minus_2 = (\n",
    "    comparisoneeg_channel_1_data - comparisoneeg_channel_2_data\n",
    ")\n",
    "comparisoneeg_channel_1_minus_2 = (\n",
    "    comparisoneeg_channel_1_minus_2 * scale_factor\n",
    ")  # To get the data to same scale as ours, v to uv\n",
    "\n",
    "comparisoneeg_filtered = do_bandpass(\n",
    "    comparisoneeg_channel_1_minus_2,\n",
    "    [config.FILTER_RANGE[0], config.FILTER_RANGE[1]],\n",
    "    config.BASE_SAMPLE_RATE,\n",
    ")\n",
    "\n",
    "idun_filtered = do_bandpass(\n",
    "    shifted_final_idun_base_arr,\n",
    "    [config.FILTER_RANGE[0], config.FILTER_RANGE[1]],\n",
    "    config.BASE_SAMPLE_RATE,\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 2))\n",
    "time_seconds = np.arange(len(shifted_final_idun_base_arr)) / config.BASE_SAMPLE_RATE\n",
    "plt.plot(time_seconds, shifted_final_idun_base_arr, label=\"idun\")\n",
    "plt.plot(time_seconds, 0.5 * comparisoneeg_channel_1_minus_2, label=config.DEVICE)\n",
    "plt.legend()\n",
    "plt.title(\"Raw and synced data\")\n",
    "plt.xlabel(\"Time in seconds\")\n",
    "plt.ylabel(\"Amplitude in uV\")\n",
    "plt.ylim(-100, 100)\n",
    "plt.savefig(os.path.join(folder, subject, night, f\"{subject}_{night}_raw.png\"))\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 2))\n",
    "time_seconds = np.arange(len(idun_filtered)) / config.BASE_SAMPLE_RATE\n",
    "plt.plot(time_seconds, idun_filtered, label=\"idun\")\n",
    "plt.plot(time_seconds, 0.5 * comparisoneeg_filtered, label=config.DEVICE)\n",
    "plt.legend()\n",
    "plt.ylim(-100, 100)\n",
    "plt.title(\"Filtered and synced data\")\n",
    "plt.xlabel(\"Time in seconds\")\n",
    "plt.ylabel(\"Amplitude in uV\")\n",
    "plt.savefig(os.path.join(folder, subject, night, f\"{subject}_{night}_filtered.png\"))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 2))\n",
    "time_seconds = np.arange(len(idun_filtered)) / config.BASE_SAMPLE_RATE\n",
    "plt.plot(\n",
    "    time_seconds[x_start_index : x_start_index + range_viz_index],\n",
    "    idun_filtered[x_start_index : x_start_index + range_viz_index],\n",
    "    label=\"idun\",\n",
    ")\n",
    "plt.plot(\n",
    "    time_seconds[x_start_index : x_start_index + range_viz_index],\n",
    "    0.2 * comparisoneeg_filtered[x_start_index : x_start_index + range_viz_index],\n",
    "    label=config.DEVICE,\n",
    ")\n",
    "plt.legend(\"lower right\")\n",
    "plt.ylim(-25, 25)\n",
    "plt.title(\"Filtered data\")\n",
    "plt.xlabel(\"Time in seconds\")\n",
    "plt.ylabel(\"Amplitude in uV\")\n",
    "plt.grid()\n",
    "plt.savefig(\n",
    "    os.path.join(folder, subject, night, f\"{subject}_{night}_filtered_zoom.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a time array based on config.BASE_SAMPLE_RATE and length of prodigy_filtered\n",
    "time_array = np.linspace(\n",
    "    0,\n",
    "    len(shifted_final_idun_base_arr) / config.BASE_SAMPLE_RATE,\n",
    "    len(shifted_final_idun_base_arr),\n",
    ")\n",
    "# copy the shifted_final_prodigy_base_df\n",
    "synced_base_df_copy = copy.deepcopy(shifted_final_comparisoneeg_base_df)\n",
    "# add shifted_final_idun_base_arr as \"IDUN\" column to prodigy_base_df_copy\n",
    "synced_base_df_copy[\"IDUN\"] = shifted_final_idun_base_arr\n",
    "# make index of prodigy_base_df_copy as time_array\n",
    "synced_base_df_copy.index = time_array\n",
    "\n",
    "# save the dataframe as csv, and add a header indicating the sampling rate\n",
    "save_path = os.path.join(folder, subject, night, f\"{subject}_{night}_synced_data.csv\")\n",
    "synced_base_df_copy.to_csv(save_path, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idn-sync-data-pWEap7XJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
